% ************************************************************************
%
% Introduction
%
% ************************************************************************
\chpos{22mm}{10mm}

\chapter[Introduction]{Introduction}
\markboth{\thechapter\ \ Introduction}{\thechapter\ \ Introduction}
\label{ch1:introduction}

%\mysquote{0.8\textwidth}{Quote text.}{Author (\oldstylenums{1000} - \oldstylenums{1100})}

% ************************************************************************
%https://www.quantamagazine.org/why-the-first-drawings-of-neurons-were-defaced-20170928/
%https://www.npr.org/sections/health-shots/2017/01/26/511455876/art-exhibition-celebrates-drawings-by-the-founder-of-modern-neuroscience
%https://www.nytimes.com/2018/01/18/arts/design/brain-neuroscience-santiago-ramon-y-cajal-grey-gallery.html
%https://www.brainpickings.org/2017/02/23/beautiful-brain-santiago-ramon-y-cajal/
\section{Neuron cell reconstruction} % 
\lettrine{F}{ascination} with the neuron cells dates to the pioneering investigation over a century ago when a glance into the sample of silver-stained brain tissue made it possible to disclose the intricate network that forms the very essence of the nervous system. Remarkable milestone drawings of Santiago Ram\'{o}n y Cajal \cite{ramon2008histologia} - the founding father of neuroscience, remain as vivid as the images acquired by the latest state-of-the-art fluorescence microscope. Ever since the breakthrough, numerous studies \cite{ascoli2001computer,defelipe2002microstructure,defelipe1992pyramidal,van2001need,scorcioni2004quantitative,mason2007initiation,gensel2010semi,markram2015reconstruction} have practiced using morphological features of the neurons to gain a deeper insight into various aspects of the functionality. Today seen as revolutionary, hundred years old hand-made illustrations depicting microscope-magnified samples of the brain tissue \cite{swanson2017} displayed exceptional level of detail. The insights comparable to the ones provided with the modern expert-assisted digital reconstructions obtained using the latest equipment, rendered with the newest computer graphics. For the years that came the discipline gradually established as neuroscience \cite{kandel2000principles}. Furthermore, the astounding advancement of electrical engineering and computer science laid out the foundations for more specialized disciplines such as neuroinformatics and neural engineering (Fig.~\ref{ch1_fig1}). Recently, the attention is directed towards brain science - domain dedicated to the investigation of the captivating mechanism of, arguably, one of the most complex and mysterious organs. The disclosure of Cajal's groundbreaking \textit{neuron doctrine}\footnote{Every neuron in the brain is separate. Neuron cells conduct information in a defined direction and communicate across the synapses \cite{glickstein2006golgi}.} brought to light the idea that the nervous system is a network composed of the building blocks called neuron cells. Each cell (Fig.~\ref{ch1_fig7}) further represents sophisticated, interconnected processing component that both transmit and process the information. Different cells have different roles and hence varying properties, including the topology. The network structure is very important and offers the possibility to grasp useful evidences related to the functionality.

Physical materialization of the cell portrays the inner structure of the neuronal tissue and yields a valuable insight into the mechanisms behind the nervous system. Various studies have been carried out in order to understand neuron behavior and further unravel the underlying principles. Hence, the knowledge of neuron morphology provides with an essential resource for specialized analysis that can typically include (examination of the changes in neuronal structure) (reactions, studying response) caused by the external stimuli \cite{gomez2007immobilized,koppes2011neurite}, modeling \cite{ascoli2001computer}, statistical analysis \cite{polavaram2014statistical}, describing connectivity patterns \cite{}, cataloging neuron phenotypes (identities) \cite{defelipe2013new}, classification of neuron types \cite{armananzas2015towards}, simulating electrophysiological behavior \cite{} or the statistical analysis \cite{samsonovich2005statistical}. Widely used Sholl analysis methodology \cite{sholl1953dendritic} makes the direct use of the digital neuron reconstructions as a blue print of the morphology. It is commonly used in neuroscientific experimentation for quantitative analysis of the morphological characteristics of the neuron \cite{garcia2014new}. Aforenamed neuroscientific studies directly rely on accurate knowledge of 3D neuronal morphology which can not be depicted with a raw data image stack but requires comprehensive and precise specification \cite{parekh2013neuronal}.

\begin{figure}
	\begin{center}
		\includegraphics[width=\textwidth]{ch1_fig1}
	\end{center}
	\caption{Timeline overview of the selected relevant achievements concerning to the neuron cell analysis. The impact of the electrical engineering and the computer science is crucial for the great achievements in recent past.}
	\label{ch1_fig1}
\end{figure}

Neuron cell thus represents a core building block of the brain and the nervous system. It appears in variety of shapes (Figure~\ref{ch1_fig7}) and specializations \cite{ascolitrees}. The estimated number of neuron cells in a human brain amounts to striking 89 billion \cite{herculano2009human} - number comparable to the count of stars in the Milky Way galaxy. The dimension of each neuron can range from a few to several tens of micrometer with the neurite branch diameter typically measured in $\mu m$ scale. Each neuron is further connected to 50 thousand other neurons on average which results in an extremely powerful computational network and an very efficient information storage device. Intriguing mechanism of the brain functioning has recently emerged as an important research topic as the complex functionality of the brain defines much of the living organism activities, even the those abstract and subjective such as consciousness. Modeling the brain functionality is one of the grand unanswered questions of our era and central to diverse fields such as physics, mathematics, biology and recently prominent - computer science \cite{markram2015reconstruction}.

Neuron analysis gear has been adopting to the advancements of technical infrastructure available for the experimentation. Numerous technical obstacles have nevertheless persisted when reaching out to record the neuronal sample. This is primarily due to the physical and physiological difficulties and the generally intangible functioning mode of the nervous system. With the early analogue computers \cite{glaser1965semi}, it became possible to connect computer with microscope and automate tracing using analogue linear motion transducers as well as significantly speed up gathering of the information about the dendritic and axonal patterns. Subsequent generations of digital computers \cite{capowski1981accurate,capowski1977computer} brought further advances in the neuron reconstruction technique by introducing the computer graphics mixed with the neuron image and the advanced operator controls such as 3D joystick. The expansion of home PC hardware and software in late decades of the 20th century increased the impact of the informatics \cite{halavi2012digital}. Breakthrough of the conventional PCs made it feasible to throughput more computation and eventually implement in practice the algorithms that, although previously discovered, could not be directly implemented and shared between the users on a needed scale. It also marks the period when the first commercial and open-source academic software solutions emerge and grow (Fig.~\ref{ch1_fig1}) which to this day proved to be a steady trend.
% In decades following the emergence of neuroscience, the instrumentation has been a limiting factor to the amount and the variety of the morphologic data that could be gathered \ref{ch1_fig1}. At the beginning of the second half of the 20th century, conventional electronic analog techniques were used to join microscope and the analogue computer to automate the neuron morphology quantification.

\begin{figure}[t!]
	\begin{center}
		\includegraphics[width=\textwidth]{ch1_fig7}
	\end{center}
	\caption{Example neuronal branching arbors selected from the NeuroMorpho.org database. Showcase the topological diversity across multiple species, brain regions, and laboratories worldwide. Renderings exported using web-based neuron morphology viewer \cite{bakker2016web}.}
	\label{ch1_fig7}
\end{figure}

The crucial engineering tasks concerning the neuron reconstruction are: 1) need for the reduction of the time interval needed to compute the digital reconstruction and 2) most accurate possible reconstruction using often challenging data. The astonishing increase in the volume of acquired microscopy imaging data \cite{meijering2016imagining} undoubtedly raised the requirements bar when it comes to the time needed to for the reconstruction as images are increasingly larger and dedicated algorithms are needed to cope with the sized image volumes \cite{peng2017automatic}. Wide variety of neurons imaged under different modalities of the light microscopy (dark-field, bright-field, confocal) are still challenging for automated processing \cite{svoboda2011past,peng2011proof} and plethora of the reconstruction methods \cite{peng2011automatic} have ever since dealt with this task, resulting in two grand challenges such as DIADEM\footnote{http://diademchallenge.org} (``digital reconstruction of axonal and dendritic morphology'') and BigNeuron\footnote{http://bigneuron.org} \cite{peng2015diadem,peng2015bigneuron,gillette2011diademchallenge} (Fig.~\ref{ch1_fig1}) intended to stimulate the community effort and improve the overall state-of-the-art. In spite of the great advancements in the field, both tasks are yet very actual.

The physical appearance of the neuron cells takes part in the nervous system activity. Morphology of the single cell, shape of the neuronal network, topology or connectivity react to the external conditions or external stimuli. With the imaging tools such as fluorescence microscopy, the physical appearance the morphology of the single cell can be captured at micro meter scale can be inspected and recorded. Indeed, the studies that require deeper analysis make use of the imaging techniques that can reach nano meter scale, such as electron microscopy. In other words, accurate quantification of the cell shape is an important step towards better understanding of the cell functionality. Quantification of the neuronal structure is crucial in many neuroscience studies \cite{halavi2012digital} and quantification from microscopic images is identified as one of the major technical challenges in the digital era of neuroscience \cite{peng2015diadem}.

The advancements in informatics made it possible (Fig.~\ref{ch1_fig1}) to utilize computers to solve the neuroinformatics challenges over recent decades. With the ever growing amount of data, the processing of the information remains a challenge.   

\section{Capturing neuron morphology}
Typically, imaging neurons consists of three main stages \cite{peng2015bigneuron}. First, the neuron sample is labeled in order to expose the structure, then the digital images are acquired using one of the microscopy modalities. Finally, the obtained neuron images are computer processed. In addition, the algorithms often require to be customized in order to address a particular biological question or be used in wider range of biological questions under wider range of image types which often prevents them from being used across different laboratories. The key obstacles in reaching the ubiquitous, accurate and robust automation of the neuron reconstruction \cite{meijering2010neuron,donohue2011automated,acciai2016automated} can be seen through the number of hampering factors which concern both the intricate nature of the data and the barriers imposed by the imaging modality. In this regard, it is possible to identify some major hurdling items.

\textit{Morphology} of the neuron cell is remarkably diverse (Fig.~\ref{ch1_fig7}). The structural intricacy of the complex examples can be challenging, even to the human visual comprehension. High complexity requires large amount of hours needed for manual delineation which thus inevitably becomes more error-prone. Hence the need for constant improvement of the computer vision algorithms. The aim of the methods is to reduce the manual labor time while fabricating trustful reconstructions. For instance, the 20-fold speedup of the reconstruction time compared to the manual reconstruction had been projected in earlier challenges \cite{liu2011diadem}.

\textit{Imaging} neurite arbor using different variations of light microscopy has been widely accepted choice for inspecting the cell structure \cite{meijering2010neuron,donohue2011automated}. Capturing $\mu$m scale objects (e.g. neurite diameter \cite{ascolitrees}), however, introduces imaging limitations. Optical systems suffer from the diffraction limit resulting in the single-lens imaged object point source being transmitted as the airy pattern \cite{cox2012optical}. In practice, the point source produces the point-spread function (PSF) which under reasonable assumptions can be approximated with the Gaussian \cite{zhang2007gaussian}. Nevertheless, the lateral resolution in fluorescence microscopy is such that the neurite dimensions are not substantially higher than the imaging resolution limits (sub-$\mu$m) which can be a limiting factor. Axial spatial resolution ($xy$ plane), on the other hand, is yet even (multiple times) lower as the precision is lost in the transition when imaging different stack layers ($z$ axis resolution). Eventually, the imaging process is predominantly affected by the particle-count driven photon noise \cite{van1998digital}, modeled with the Poisson process. Thus, the Poisson distribution is further used in generating synthetic microscopic images \cite{smal2010quantitative}. In accordance with the earlier studies, signal-to-noise ratio (SNR) of the microscopic image is expressed as the ratio of the intensity inside neuron above the background and the standard deviation of the noise inside neuron \cite{cheezum2001quantitative,smal2010quantitative}. Besides optical ``blurring'', neuron imaging can comprise pixelisation with the large spatial extent of the neuron. Combining together the optical magnification with the limited size of the digital matrix used to store the recording, as a consequence -the voxel size becomes larger that the PSF resulting in partial volume effect.% particles and debris can be erroneously detected as neuron structures

Burden of the ever increasing \textit{data volume size} tends to counterbalance the increased memory and processing speed of commonly available modern computers. Although the automated tracing of the neuron morphology has substantially improved over the recent years, the existing methods do not scale satisfactory in terms of the processing speed and the accuracy with the increased dimensionality of the data. Typically, the methods are challenged if applied on (datasets with) very large neuronal image stacks \cite{peng2017automatic}. Consequently, the image volume size represents a significant challenge for the computer vision methods. Dedicated strategies, such as extending the existing neuron tracing algorithms in order to be able to trace the unlimited data volumes \cite{peng2017automatic}, processing of the stitched imagery, or iteratively tracing in adjacent image tiles \cite{zhou2015neuron} have been introduced.% The objective to stay accurate and processed in reasonable time

\textit{Gold standard} of the neuron reconstruction is not an unique absolute digital representation of the image, but rather an (considerably subjective) approximation of the existing morphology. Often, the gold standard expert annotations are semi-automatic - thus obtained aided with various established tracing tools \cite{ascoli2007neuromorpho} both non-commercial such as NeuronJ \cite{meijering2004design}, open-source Vaa3D \cite{peng2014extensible} or the commercial packages such as Neurolucida (MBF Bioscience) or Amira (Thermo Fisher Scientific). With the often intricate structure of neuronal arbor, the expert annotations can differ and should be interpreted as a one among possible versions. Attempts to reach a consensus annotation by bringing together gold standards from different sources \cite{peng2015bigneuron}. Hence, the subsequent corrections (proof-editing) are often crucial in reaching better quality \cite{peng2011proof}. To have the optimal results in practice, additional expert corrections are often essential \cite{peng2011proof}. One way to overcome the obstacle is to use the consensus from several available gold-standard reconstructions as a better choice. Such scenario requires further definition on how the consensus would be computed. If the study concentrates on benchmarking the image analysis methods, synthetic neuron images can be generated from the existing reconstructions as the ground truth \cite{koene2009netmorph,radojevic2015fuzzy,radojevic-pnr}. This way, there is no need for multiple reconstruction sources as the real ground truth is known through reverse engineering.% \textit{Dynamic images} Analysis of the images captured from the live neuronal cultures.

Aforementioned characteristics impose much of the barrier in attempt to consistently and efficiently produce digital reconstructions comparable with the expert ones.

\begin{figure}
	\centering
	\begin{tabular}{c@{\hspace{1em}}c@{\hspace{1em}}c@{\hspace{1em}}}
		\includegraphics[width=0.25\textwidth]{ch1_fig2a} & 
		\includegraphics[width=0.25\textwidth]{ch1_fig2b} & 
		\includegraphics[width=0.25\textwidth]{ch1_fig2c} \\
		a) Shortest path tracing & b) Minimum spanning tree & c) Path-pruning
	\end{tabular}
	\caption{Examples of the essential neuron reconstruction strategies: a) Finding optimal path having two control points, b) Inferring the  optimal tree structure from the set of nodes c) Pruning the over-complete neuron tree.}
	\label{ch1_fig2}
\end{figure}

% reconstruction components: trace, seed point, ancor point, lanmark, blob, tree
\section{Reconstructions from light microscopy}
Strategies for neuron single cell reconstruction employ different (algorithmic) approaches. Vast majority of the introduced work treats tree reconstruction as loosely modular task where different algorithmic units are dedicated to handle particular tree components. Nevertheless, there is inevitably a degree of commonality and interdependence as the cascade of the methods requires outputs the used computation stages to be used in the follow up steps. The reconstruction accuracy also depends on the algorithmic ability to generalize well which does involve undertaking a fair share of parallelized processing. Extensive amount of the methodologies introduced over the years \cite{meijering2010neuron,donohue2011automated,acciai2016automated} can be broadly cast into three general approaches (strategies) (Fig.~\ref{ch1_fig2}) where each strategy emulates various optimization tasks: neurite tracing as an optimal path between given endpoints (Fig.~\ref{ch1_fig2}a), finding an optimal tree from the set of given landmark points that already belong to the tree (extracting the most accurate tree from the given set of guide points Fig.~\ref{ch1_fig2}b) and over-tracing/over-representing the tree (Fig.~\ref{ch1_fig2}c). As one might presume, the methodological separation cannot be absolutely rigorous. It is very likely for the methods to combine together different ideas and overlap in terms of the approach.

Neurite branch tracing could be interpreted as the energy/cost minimization problem \cite{meijering2004design,peng2010automatic} used to extract the trace or to refine the existing one. Classic example of neurite tracing is computing an optimal (shortest) path through the existing voxel grid where the designed geodesic metric or cost function has been defined to weigh the transition between grid elements (graph vertices). Such processing strategy has been particularly ubiquitous in practice \cite{meijering2004design,peng2010v3d,longair2011simple}, notably for semi-automated tasks where the control points of the optimized trace are initially known or had been computed. Notable tracing approaches are geodesic shortest path \cite{peng2010automatic} or live-wire segmentation \cite{meijering2004design} solved using Dijsktra shortest-path algorithm \cite{dijkstra1959note} - a methodology well established in tracing curvilinear structures. The downside of tracing defined in this manner is the necessity of having starting points, trace endpoints or correct initialization which can be challenging and require global image reasoning. Computed curve can further be refined with energy minimization and solved using gradient descent optimization \cite{peng2007straightening,peng2010automatic}. 

Given the output format used to store the digital reconstruction result (explained in more detail in Section~\ref{ch1_sec4}), digital neuron tree consists of the set of connected discrete neuron compartments (spherical nodes). Neuronal compartment would hence correspond to the cross-section of the branch segment. The essential geometrical quantities computed during tracing are the compartment 3D center $\mathrm{p} = (x, y, z)$ and the local (sphere) radius $r$ which would relate to the diameter of the segment. Depending on the tracing approach, neuron nodes can be also assigned with the direction $ \mathrm{v} = ( v_x, v_y, v_z ) $ computed at $\mathrm{p}$. The cumulative cost function used to steer the tracing toward an optimal solution is used within the optimization scheme and computed over the tract components. Aside from the geometrical constrains, also needs to include (take into account) the values extracted from the image - i.e. locally sampled/interpolated image intensity, or some other custom designed measure computed using (by filtering) local image intensities over the spatial extent of the node $\mathrm{x}$. For a more in-depth illustration, it is useful to introduce a vector $\mathrm{x} = \left[  \mathrm{p}, r, \mathrm{v} \right] $ combining all geometrical elements of the neuron compartment together. Sequence of digital neurite nodes $\mathrm{X} = \left\lbrace \mathrm{x}_1, ... , \mathrm{x}_i, ..., \mathrm{x}_N \right\rbrace$ would concatenate together the nodes that correspond to a digitized neurite tract (trace). Cumulative cost (Eq.~\ref{ch1_eq3}) computed over the tract would result in a measure whose minimization results with an optimal trace. Cost defined such way can be also used to define the energy being minimized to further refine the trace.%  using gradient descent 

%\begin{equation}
%C(\mathrm{X}) = \int_{\mathrm{X}} c( \mathrm{x}, I(\mathrm{x}) ) d\mathrm{x}
%\end{equation}
%The trace segment with $L$ elements can be  $\mathrm{X}_L = \left\lbrace \mathrm{x}_i \right\rbrace, 1 \leq i \leq L $ containing $L$.

\begin{equation}
C(\mathrm{X}) = \sum\nolimits_{i} c(\mathrm{x}_i, I(\mathrm{x}_i)) \Delta\mathrm{x} 
\label{ch1_eq3}
\end{equation}

Cost function $ c( \mathrm{x}, I(\mathrm{x}) ) $ (Eq.~\ref{ch1_eq3}) typically represents a weighted score of the set of geometry and intensity based components. If expressed with two constituents for the illustration purpose, cost function would further decompose into:

\begin{equation}
c(\mathrm{x}, I(\mathrm{x})) = \alpha c_{\iota}(\mathrm{x}, I(\mathrm{x})) + (1-\alpha) c_{\gamma}(\mathrm{x}) 
\label{ch1_eq4}
\end{equation}

where $c_{\gamma}$ corresponds to the geometry-based and $c_{\iota}$ to an intensity-based component, with weight $ \alpha \in \left[ 0, 1 \right] $. 

The intensity-based component can directly use the sampled voxel intensities:
\begin{equation}
c_{\iota}( \mathrm{x}, I(\mathrm{x}) ) = I(\mathrm{x})
\end{equation}

where $I(\mathrm{x}) = I(\mathrm{p}) = I(x, y, z)$ represents the voxel intensity at given location. Alternatively, the exponential of the inverse intensity of pixels along the path can be used to define the cost \cite{peng2010automatic}:
\begin{equation}
c_{\iota}( \mathrm{x}, I(\mathrm{x}) ) = \text{exp} \left(  \lambda  (1 - \tilde{I}(\mathrm{x}))^2 \right)
\end{equation}

where $\tilde{I}(\mathrm{x})$ represents the normalized intensity value $ \tilde{I}(\mathrm{x}) = \tilde{I}(\mathrm{p}) = \tilde{I}(\mathrm{p}) / I_{\text{max}}$, with $\max_{\substack{\forall \mathrm{p}}} I(\mathrm{p})$.

The custom tubularity measure $\rho$ can also be used to weight an intensity-based component:
\begin{equation}
c_{\iota}( \mathrm{x}, I(\mathrm{x}) ) = \rho(\mathrm{p}) = \rho(x, y, z)
\end{equation}

where $ \rho $ denotes the computed tubularity measure. If obtained over set of scales $\Sigma$, it becomes $\rho_{\Sigma}$ with $\Sigma = \left\lbrace \sigma_k \right\rbrace$, $1 \leq k \leq K$ used to denote the scales $\sigma$ used when filtering. Ratios of the Hessian eigen values obtained at different scales $\sigma_k$ are used to determine the scalar intensity which highlights the tubular structures \cite{sato19973d,meijering2004design,frangi1998multiscale}. Also the scale-space analysis of the line profile model \cite{steger1998unbiased} can be used. Thanks to the Hessian analysis, the tubularity measure can incorporate the local direction of the filtered tube-like structure. Tubularity measures are commonly computed at pre-filtering aiming to reduce the presence of noisy, non-tubular structures. Tubularity measure calculated this way is deterministic and unsupervised  which implies usage of the predefined computation recipe regardless of the input data. Moreover, calculating the tubularity measure can also be cast as a supervised learning problem \cite{sironi2016multiscale,li2017deep} enabling tubularity measure to adopt to a particular problem based on the training. The practical downside of such approach, aside from designing the most suitable machine learning model, is that it requires dedicated training which in practice can be time and resource consuming.%closeness to local centers of image intensity distribution

Trace refinement can be based on the discrepancy of the node locations from the centers of the intensity distribution. Minimizing the energy computed as in Eq.~\ref{ch1_eq2} is used to further align the curve to the underlying image intensities.  
\begin{equation}
c_{\iota}(\mathrm{x}_i, I(\Theta(\mathrm{x}_i))) = \text{exp} \left( \lambda \frac{ \sum\nolimits_{\mathrm{y} \in \Theta(\mathrm{x}_i)} \lVert \mathrm{x} - \mathrm{y} \rVert^2 I(\mathrm{y}) \Delta\mathrm{y}  }{\sum\nolimits_{\mathrm{y} \in \Theta(\mathrm{x}_i)} I(\mathrm{y}) \Delta\mathrm{y} } \right) 
\label{ch1_eq2}
\end{equation}

$\Theta(\mathrm{x}_i)$ of the Eq.~\ref{ch1_eq2} denotes the local spatial neighborhood of the spherical node compartment $\mathrm{x}_i$. Such refinement scheme equates to the image intensity based mean-shift \cite{cheng1995mean} of the node location, which can also be used to refine a collection of the overlapping tracings \cite{radojevic-pnr}.

Zero-mean normalized cross-correlation (ZNCC) is a normalized, contrast-independent measure used to quantify the similarity of the encountered intensities sampled within the node compartment with the given spatial intensity distribution model.
\begin{equation}
c_{\gamma}(\mathrm{x}_i, \Phi(\mathrm{x}_i)) = \frac{ \sum\limits_{\mathrm{p} \in \Phi(\mathrm{x}_i)} (I(\mathrm{p}) - \bar{I}(\mathrm{p}))(G_{\sigma}(\mathrm{p}) - \bar{G}_{\sigma}) }{ \sqrt{ \sum\limits_{\mathrm{p} \in \Phi(\mathrm{x}_i)}(I(\mathrm{p}) - \bar{I}(\mathrm{p}))^2 \sum\limits_{\mathrm{p} \in \Phi(\mathrm{x}_i)}(G_{\sigma}(\mathrm{p}) - \bar{G}_{\sigma})^2 } }
\label{ch1_eq1}
\end{equation}

$\Phi(\mathrm{x}_i)$ represents the spatial neighborhood of the node compartment $\mathrm{x}_i = [ \mathrm{p}, \mathrm{v}, \sigma ]$, commonly defined as the tube cross-section cylinder centered at $\mathrm{p}$, having $\sigma$ radius and directed along $\mathrm{v}$. $\bar{I}$ and $\bar{G}$ are the respective mean values of the intensities inside the sampled region $\Phi$. $G_{\sigma}$ denotes the spatial intensity distribution model at given scale (cylinder radius) $\sigma$. In case of neurons - a Gaussian intensity profiles in the cylinder cross-section plane are a reasonable choice \cite{radojevic2017neuron}. 

The geometry-based component can incorporate the vectorial (directional) alignment of the centroids along the filtered tubularity direction \cite{meijering2004design}:  
\begin{equation}
c_{\gamma}(\mathrm{x}) = c_{\gamma}(\mathrm{x}_{i}, \mathrm{x}_{i+1}) = 1/2 \left( \varphi(\mathrm{p}_i, \mathrm{p}_{i+1})^{\frac{1}{2}} + \varphi(\mathrm{p}_{i+1}, \mathrm{p}_{i})^{\frac{1}{2}} \right) 
\end{equation}
where $\varphi( \mathrm{p}_{i}, \mathrm{p}_{j} ) = | \mathrm{v}_i \cdot \mathrm{u}_{ij} |  $ quantifies the alignment of the curve - amount of the directional overlap of the local tubularity direction with the unit link vector between the two points $\mathrm{u}_{ij} = (\mathrm{p}_j - \mathrm{p}_i) / \lVert \mathrm{p}_j - \mathrm{p}_i \rVert $. Furthermore, the geometry-based measure such as the digital trace smoothness \cite{peng2010automatic} or bending energy \cite{radojevic2015fuzzy} is derived using the topological information:
\begin{equation}
c_{\gamma}(\mathrm{x}) = c_{\gamma}(\mathrm{x}_{i-1}, \mathrm{x}_{i}, \mathrm{x}_{i+1}) = \sum\nolimits_{i} (- \mathrm{p}_{i-1} + 2\mathrm{p}_i - \mathrm{p}_{i+1})^2 \Delta\mathrm{p}
\end{equation}

Besides Dijkstra shortest path tracing, variants of (conceptually similar) fast marching (FM) algorithm \cite{sethian1999level} have been successfully adopted to the neuron reconstruction domain \cite{xiao2013app2}. Similarly to Dijkstra shortest path, FM turned out to be particularly useful due to the ability to bridge the gaps between the disconnected neurite segments. FM solution as a fast numerical solution to the Eikonal equation, conceptually very similar to Dijkstra algorithm, has been used to gradually grow the segmented neuron region by connecting the neighboring with the growing body. Particular implementations of FM-based reconstruction method (i.e. APP2 method \cite{xiao2013app2}) have been effective in reducing the general disadvantages of the earlier versions \cite{van2007subvoxel}. Number of follow-up works report the range of improvements related to tracing the discontinuous areas, namely the using gradient descent \cite{mukherjee2012automated}, or back-propagation  \cite{liu2016rivulet}.

Active contour based methods are particularly attractive for this work. They are among the most widely used segmentation methods that have also been employed for neuron tracing.
or energy minimization methods such as open-curve snake using gradient-vector flow
\cite{schmitt2004new}
 \cite{wang2011broadly} have been used in neuron tracing.

Accurately merging the obtained traces into a tree reconstruction represents a significant challenge. Due to the complexity of the problem (many alternatives to examine) and the amount of computation needed to exhaust to reach the solution, assembling  a tree structure is typically solved as the approximation. multiple tracts and merging their shared portions.


Significant share of the methods aims at finding a globally optimal solution on the whole-tree level. Having such approach, the set of node candidates is commonly turned into a weighted graph. The reconstruction is then based on computing the optimal tree (minimum weight trees) from the established weighted graph. The widespread tool for this application is the NP-complete minimum spanning tree (MST) algorithm \cite{peng2015bigneuron}. Alternative solution is to extract minimum trees spanning subset of the graph edges. However, since finding the optimal solution is a complex NP-hard problem and involves plenty of scenarios to explore and assess, the approximative solutions are used in practice, for instance  with the  namely k-MST \cite{turetken2011automated} where 

%
Finally, the methods that employ the over-reconstruction, over-segmentation of the 

 

Global versus local processing trade-off is essential for the method success as the correct generalizations represent a true challenge.

\subsection{Bayesian filtering in neuron tracing}
Tracing neurite branches can be conceived as estimating the unknown quantities using given observations. In such  as a Bayesian filtering problem. Recursive Bayesian estimation,  Namely, the centerline, the radius solved using  where quantification of the neuron compartment values can be seen as probability density function of the... 

Bayesian reasoning relies on the assumption that the estimated unknown quantities are hidden, not measurable directly but possible to estimate (filter) their posterior distribution using given observations \cite{doucet2001introduction}. Bayesian model consists of two essential components: prediction and update \cite{ristic2004beyond}. Prediction uses exiting prior knowledge to generate the prior distribution  of the state variable, denoted with $ \{ \mathrm{x}_t $, $ t \in \mathbb{N} \} $.  $ \{ \mathrm{y}_t, t \in \mathbb{N} \} \{ \mathrm{p}(\mathrm{x} | \mathrm{y}) \} $ 

As an example, centroid (or some other) estimate of the the distribution of the distribution $\mathrm{p}(\mathrm{x})$  $\mathrm{p}(\mathrm{x} | \mathrm{y})$
offers a common generic solution for tasks that involve non-Gaussianity, high dimensionality, non-linear state-space model, where state-space cannot be Gaussian. Other names for the same concept are: (optimal nonlinear, stochastic). In essence, the approach boils down to computing posterior distributions of the values intended to be filtered. Basic algorithm applicable in different contexts. The problem is defined as the estimate the set of hidden states The approach is also convenient becuase it leaves plenty of possibilities for customization of the filtering (it can be used as a component algorithm).

Other methods used to establish optimal connections between paths.
The collection of the methods used: shortest path (i.e. Dijkstra \cite{dijkstra1959note}), fast marching, geodesic . In all of those an optimal solution to the cost is sought after. Currently, BigNeuron challenge Several notable approaches in broad sense can be differentiated.

On model-based reasoning. Why is the Gaussian cross-section model \cite{zhao2011automated,radojevic2017neuron} suitable.

% https://www.neuron.yale.edu/phpBB/viewtopic.php?t=3477
% http://www.neuromorpho.org/myfaq.jsp (What is SWC format?)
% http://research.mssm.edu/cnic/swc.html
% http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html
\section{Neuronal reconstruction format}
\label{ch1_sec4}
Once processed, neurons are typically exported into a dedicated data format intended to store the idiosyncratic tree-like topology of the cell. Among different ideas and implementations of standards used for storing reconstructed neurons, two neuron morphology file formats prevail in lab usage and recent large scale neuron related projects \cite{bakker2016web}: Neurolucida DAT format (MicroBrightField, Inc.) and SWC format \cite{cannon1998line}. Neurolucida DAT format is closed-source binary format whose reverse engineered description\footnote{http://neuronland.org} suggests neuron compartments being saved as a hierarchical tree of the linear segments. SWC format on the other hand is open-source, space delimited text format that stores tree structure in an array $\mathcal{N} = \{ n_1, \dots , n_i, \dots , n_j, \dots  \}$ where each element of the array, $n_i$, corresponds to a neuronal spherical compartment (Fig.~\ref{ch1_fig5}d). SWC, therefore, renders the reconstruction as a list of nodes (neuronal compartments) with seven attributes: node index identifier $i$, node type, sphere 3D coordinates $(x_i,y_i,z_i)$, radius $r_i$ and a parent node index (Fig~\ref{ch1_fig5}). Parent node index represents the link towards predecessor node. By convention it is set to -1 for the origin node. To conform with a tree structure, each spherical compartment may have one predecessor (parent) with lower node index ($i<j$, Fig.~\ref{ch1_fig5}). Loops and disconnected branches should not exist as that would not be in agreement with the tree-like structure. Etymologically, SWC represents the acronym containing the initials of the last names of Stockley, Wheal, and Cole. Although not directly described in their joint work on quantitative measurement and modeling of the neuron morphology \cite{stockley1993system}, the origin of the SWC name is an acronym of the initials of their last names. 

Lastly, the SWC format exhibits variations, especially concerning the unified definition of the soma reconstruction \cite{bakker2016web}. Several interpretation of the standard exist\footnote{http://research.mssm.edu/cnic/swc.html}\footnote{http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html}\footnote{NeuroMorpho.org FAQ: What is SWC format? http://www.neuromorpho.org/myfaq.jsp}. One of the downsides of the SWC format is its often oversimplified cylinder model of the soma. Being a rather simple (straightforward to implement the software to read and export) and open-source format, easy for exchange - it has been adopted by notable large-scale neuron morphology projects \cite{ascoli2007neuromorpho,peng2015bigneuron}. Some reconstruction methods even base the reconstruction methods on the SWC format \cite{feng2015neutube}.

The work showcased in this thesis will exclusively use open source SWC format.
 
\begin{figure}
\begin{center}
	\begin{tabular}{c@{\hspace{0.75em}}c@{\hspace{0.75em}}c@{\hspace{0.75em}}c@{\hspace{0.75em}}}
	\includegraphics[align=c,width=0.2\textwidth]{ch1_fig5a} & 
	\includegraphics[align=c,width=0.2\textwidth]{ch1_fig5b} & 
	\includegraphics[align=c,width=0.2\textwidth]{ch1_fig5c} &
	\includegraphics[align=c,width=0.2\textwidth]{ch1_fig5d} \\ 
	a) & b) & c) & d)
\end{tabular}
\end{center}
	\caption{Neuron morphology digital format data structure: a) Single neuron image, b) Digital reconstruction of the given neuron c) Illustration of the SWC format \cite{cannon1998line} used to store the digital reconstruction idiosyncratic tree structure $\mathcal{N} = \{ n_1, ... , n_i,..., n_j, ... \}$, d) Detailed visualization of the linear segment (truncated cone) connected pair of neuron compartments $(n_j, n_i)$ along with the component elements. Reconstruction exported using web-based neuron morphology viewer \cite{bakker2016web}.}
	\label{ch1_fig5}
\end{figure}

Measuring distances between neurons: L-measure \cite{scorcioni2008measure}, Neuro-blast \cite{wan2015blastneuron}. Distances between neurons can be based on the overlap and the inter-node metric distances.

Reconstruction tools: one of the key Java tools is the ImageJ library \cite{abramoff2004image} with method \cite{longair2011simple,pool2008neuritetracer}. Variety of other software platforms \cite{meijering2010neuron,acciai2016automated}. 

\section{Thesis outline}

\subsection{Fuzzy logic system}
Detecting characteristic points of the neuron tree structure, along with many of the concepts encountered in various domains of human knowledge, is in practice, too complex to be modeled with a concise or precise definition. This is true, for example, for expressing . Unsupervised method based on fuzzy logic, linguistic variables and set of if-then rules is used to 

dealing with such concepts through the use of fuzzy algorithms structured as a branching questionnaire.

Usage of the linguistic variables 

\subsection{Multiple hypothesis tracking}
Computation methods

Chapters include synthetic images that offer possibility of objective comparison.

This thesis primarily addresses/contributes to the need for automated methods for neuron reconstruction. 
In this thesis, methods that cope with uncertainty are showcased. The work is showcased in the domain of the neuron reconstruction and several neuron related tasks such as the object detection, namely the detection of the critical points (bifurcation and terminal) in microscopic images of neurons (Chapter~\ref{ch2:fuzzy}) and the localization  The first chapter  and probabilistic and bayesian methods are explored. The underlying idea assumes that the neuron tracing itself is never a .

\subsection{Probabilistic reconstruction}
Employs iterative tracing


The thesis is organized as follows. In Chapter 2,  . Subsequently, in Chapter 3, 

