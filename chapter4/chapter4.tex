% ************************************************************************
%
% Automated Neuron Reconstruction from 3D Fluorescence Microscopy Images 
% using Sequential Monte Carlo Estimation
%
% ************************************************************************
\chpos{15mm}{8mm}
\chapter[Automated Neuron Reconstruction from 3D Fluorescence Microscopy Images using Sequential Monte Carlo Estimation]{Automated Neuron Reconstruction from 3D Fluorescence Microscopy Images using Sequential Monte Carlo Estimation}
\chaptermark{Automated Neuron Reconstruction using Sequential Monte Carlo Estimation}
\label{ch4:pnr}
% abstract
{\small \lettrine{M}{icroscopic} images of neuronal cells provide essential structural information about the key constituents of the brain and form the basis of many neuroscientific studies. Computational analyses of the morphological properties of the captured neurons require first converting the structural information into digital tree-like reconstructions. Many dedicated computational methods and corresponding software tools have been and are continuously being developed with the aim to automate this step while achieving human-comparable reconstruction accuracy. This pursuit is hampered by the immense diversity and intricacy of neuronal morphologies as well as the often low quality and ambiguity of the images. This chapter presents a novel method developed in an effort to improve the robustness of digital reconstruction against these complicating factors. The method is based on probabilistic filtering by sequential Monte Carlo estimation and uses prediction and update models designed specifically for tracing neuronal branches in microscopic image stacks. Moreover, it uses multiple probabilistic traces to arrive at a more robust, ensemble reconstruction. The proposed method was evaluated on fluorescence microscopy image stacks of single neurons and dense neuronal networks with expert manual annotations serving as the gold standard, as well as on synthetic images with known ground truth. The results indicate that proposed method performs well under varying experimental conditions and compares favorably to state-of-the-art alternative methods.\par}
\vspace*{9em}
% ************************************************************************
\begin{publish}
	Based upon: M. Radojevi\'{c}, E. Meijering, ``Automated Neuron Reconstruction from 3D Fluorescence Microscopy Images using Sequential Monte Carlo Estimation'', \textit{Neuroinformatics}, \textit{in revision}   
\end{publish}% vol. 0, no. 0, pp.0-0, 2018.
\section{Introduction}
\label{sec:intro}
The brain is regarded as one of the most complex and enigmatic biological structures. Composed of an intricate network of tree-shaped neuronal cells \cite{ascolitrees}, together forming a powerful information processing unit, it performs a myriad of functions that are essential to living organisms \cite{kandel2000principles}. Obtaining a blue print of the architecture of this network, including the morphologies and interconnectivities of the neurons in various subunits, helps to understand how the brain works \cite{ascoli2002computational, donohue2008comparative, cuntz2010one}, including how  neurodegenerative disease processes alter its function. A key instrument in this endeavor is microscopic imaging, as it allows detailed visualization of neuronal cells in isolation and in tissue, thus providing the means to study their structural properties quantitatively \cite{senft2011brief}.

Quantitative measurement and statistical analysis of neuronal cell and network properties from microscopic data rely on the ability to obtain accurate digital reconstructions of the branching structures \cite{halavi2012digital} in the form of a directional tree of connected nodes \cite{ascoli2007neuromorpho}. The ever increasing amount of available image data calls for automated computational methods and software tools for this purpose, as manual delineation of neurons is extremely cumbersome even in single image stacks, and is downright infeasible in processing large numbers of images \cite{svoboda2011past, senft2011brief}. Automating neuron reconstruction requires solving fundamental computer vision problems such as detecting and segmenting tree-like image structures \cite{meijering2010neuron, donohue2011automated, acciai2016automated}. This is complicated by the large diversity of neuron types, imperfections in cell staining, optical distortions, inevitable image noise, and other causes of ambiguity in the image data. Consequently, with the current state-of-the-art, manual proof-editing of automatically obtained digital reconstructions is often necessary \cite{peng2011proof}. Recent international initiatives such as the DIADEM challenge \cite{gillette2011diademchallenge} and the BigNeuron project \cite{peng2015bigneuron, peng2015diadem} have catalyzed research in automated neuron reconstruction but have also clearly revealed that further improvement is still very much needed before computers can fully replace manual labor in performing this task.

The aim of the methodology presented in this chapter is to contribute to the developments in the field by proposing a novel fully automated neuron reconstruction method based on probabilistic filtering techniques. Starting from seed points that have a high probability of being centered at neuronal branches, presented method recursively traces these branches by sequential Monte Carlos estimation, using state transition and measurement models designed specifically for this purpose. This results in a series of possibly overlapping but probabilistically independent estimates of the branches, which are subsequently combined into a refined estimate of the actual branch centerlines using mean-shifting. The early versions of the method were presented at conferences \cite{radojevic2015automated, radojevic2017neuron} and one implementation of it (named Advantra) donated for inclusion in the BigNeuron benchmarking study \cite{peng2015bigneuron, peng2015diadem}. Since then the method has been improved and its software implementation and have significantly extended its experimental evaluation. A detailed description of the method is provided in this chapter, its implementation, and the experimental results, and show that it performs favorably compared to several state-of-the-art neuron reconstruction methods from the BigNeuron project as well as an alternative probabilistic method \cite{radojevic2017automated}.
\begin{figure}
	\begin{tabular}{c}
		\includegraphics[width=\textwidth]{fig1}
	\end{tabular}
	\caption{Schematic overview of the six main steps of the proposed method: (A) soma extraction, (B) seed extraction, (C) branch tracing, (D) trace refinement, (E) node grouping, (F) tree construction.}
	\label{ch4_fig1}
\end{figure}
\section{Related Work}
\label{sec:related-work}
Early methods and tools for digital neuron reconstruction were semi-automatic and required extensive manual intervention for their initialization and operation or the curation of faulty results \cite{glaser1965semi, capowski1981accurate, glaser1990neuron, masseroli1993quantitative}. With the increasing capabilities of computers it became possible to store and process 3D images of neurons \cite{cohen1994automated, belichenko1995confocal}. More recently, the state-of-the-art in the field has moved towards full automation of neuron reconstruction, and various freely available software tools are now available for this purpose \cite{peng2010v3d, longair2011simple, peng2014extensible, peng2014virtual}, though the need for flexible editing tools has remained unabated \cite{luisi2011farsight, dercksen2014filament}.

Neuron reconstruction methods typically have a modular design where each module or stage of the processing pipeline deals with different structural objects. Depending on the subproblems being solved, modules can operate independently, or work together for example to combine local and global processing, possibly requiring multiple iterations. Several subproblems that can be identified in the literature include image prefiltering and segmentation \cite{zhou2015adaptive, turetken2011automated, sironi2016multiscale, mukherjee2013vector}, soma (cell body) detection and segmentation \cite{quan2013neurogps}, landmark points extraction \cite{al2008improved, wang2011broadly, choromanska2012automatic, su2012junction, radojevic2016fuzzy}, neuron arbor tracing \cite{zhao2011automated, liu2016rivulet, leandro2009automatic, radojevic2017automated, xiao2013app2}, and assembling the final tree-like graph structure \cite{zhou2016tremap, turetken2011automated, yuan2009mdl}. The techniques for solving each of these subproblems are briefly reviewed in the remainder of this section. Since presenting a novel method is the primary goal of this chapter, the review is not meant to be exhaustive, but to put the new method into context.

The pool of neuron reconstruction methods is very diverse \cite{meijering2010neuron, donohue2011automated, acciai2016automated, peng2015bigneuron} but there are also many commonalities. For example, image prefiltering to enhance tubular structures is typically carried out using Hessian or Jacobian based processing \cite{xiong2006automated, al2008improved, yuan2009mdl, wang2011broadly}. And to cope with uneven staining, adaptive thresholding \cite{zhou2015adaptive}, perceptual grouping \cite{narayanaswamy20113}, and vector field convolution \cite{mukherjee2015tubularity} have been used. For image segmentation (separating foreground from background), a wide variety of methods has been proposed, including the use of feature-based classifiers \cite{turetken2011automated, chen2015smarttracing, jimenez2015improved}, tubularity based supervised regression \cite{sironi2016multiscale}, and even deep learning \cite{li2017deep}. The general difficulty of supervised methods, however, is their need for extensive manual annotation for training to arrive at usable segmentation models. This is avoided in the proposed method by using carefully designed explicit models.

For the detection and segmentation of the neuronal somas, which typically have a much larger diameter than the dendritic and axonal branches, a simple and efficient solution is to apply morphological closing and adaptive thresholding \cite{yan2013automated}. An alternative is to use shape fitting approaches \cite{quan2013neurogps}. Next, to initialize and/or guide the segmentation of the arbor, landmark points are often extracted using image filters that specifically enhance tubular structures \cite{wang2011broadly, turetken2011automated, choromanska2012automatic, su2012junction, radojevic2016fuzzy}, a popular one being the so-called ``vesselness filter'' \cite{frangi1998multiscale}. Classical approaches have been adopted for soma and seed point detection throughout the proposed method, as detailed in the next section.

Segmentation or tracing of all branches of the dendritic and axonal trees is the main challenge of the reconstruction problem. A widely used approach to overcome the difficulties caused by imperfect staining and image noise is to use techniques that find globally optimal paths between seed points by minimizing a predefined cost function \cite{meijering2004design, peng2011automatic, longair2011simple, quan2016neurogps}. But many other concepts have been proposed as well, including model fitting \cite{schmitt2004new,zhao2011automated}, contour extraction \cite{leandro2009automatic}, active contour segmentation \cite{wang2011broadly, luo2015neuron}, level-set or fast-marching approaches \cite{xiao2013app2, basu2014reconstructing}, path-pruning from oversegmentation \cite{peng2011automatic}, distance field tracing \cite{yang2013distance}, marching rayburst sampling \cite{ming2013rapid}, marked point processing \cite{basu2016neurite}, iterative back-tracking \cite{liu2016rivulet}, and learning based approaches \cite{chen2015smarttracing, gala2014active, santamaria2015automatic}. The works presented in previous chapters of this thesis \cite{radojevic2015automated, radojevic2017automated, radojevic2017neuron} have shown the great potential of probabilistic approaches to neuron tracing which formed the basis for the new fully automated neuron reconstruction method presented and evaluated in the next sections.

The final aspect of neuron reconstruction is the assembling of the complete neuronal tree structure from possibly many partial or overlapping traces and putting it into a format that is both representative and suitable for further automated analysis. This is typically solved by graph optimization strategies such as the minimum spanning tree (MST), the alternative K-MST \cite{turetken2011automated, gonzalez2010delineating}, or integer programming \cite{turetken2013reconstructing}. To deal with very large data sets it has also been proposed to assemble the 3D graph representation through tracing in 2D projections and applying reverse mapping \cite{zhou2016tremap}. However, with the advent of sophisticated assemblers such as UltraTracer \cite{peng2017automatic}, it is possible to extend any base tracing algorithm to deal with arbitrarily large volumes of neuronal image data \cite{peng2017automatic}. Therefore, the projections are not used in the method proposed in this chapter. Instead, the tracing is performed in the original image (sub)volumes. And to obtain the graph representation a new approach is proposed to refining and grouping the individual traces.

\section{Proposed Method}
\label{sec:method}

The pipeline of the proposed method consists of six steps (Fig.~\ref{ch4_fig1}) described in detail in the following subsections. The basic underlying assumption suggests that image stacks contain a single neuron (one soma) or just an arbor (no soma) as in the DIADEM \cite{brown2011diadem} and BigNeuron data \cite{peng2015bigneuron}. In short, the soma is extracted first and a set of seeds, which serve to initialize the probabilistic branch tracing scheme. The resulting traces are iteratively refined and their corresponding nodes spatially grouped into a representative node set that is traversed to form the final reconstruction.

\subsection{Soma Extraction}
\label{subsec:soma-extraction}
The soma typically has a considerably larger diameter than the individual branches of the neuronal arbor (Fig.~\ref{ch4_fig1}A). Thus it can be easily extracted using morphological filtering operations \cite{yan2013automated}. Specifically, in the method showcased in this chapter, grayscale erosion is applied to remove all branches and leave only the (eroded) soma. To this end, the radius $r_s$ of the structuring element needs to be larger than the largest expected branch radius in a given data set, and smaller than the expected soma radius. The resulting image is then smoothed using a Gaussian filter with standard deviation equal to $r_s$ and segmented using max-entropy thresholding \cite{radojevic2016fuzzy} to obtain a blob corresponding to the soma. For computational efficiency both the erosion and the Gaussian smoothing operation are carried out by separable filtering. In this chapter the soma is modeled in the final graph representation of the neuron as a single spherical node with position equal to the centroid of the segmented blob and radius equal to the average distance of the blob voxels to the centroid. Alternatively, the soma could be modeled with a set of nodes that together represent the blob as accurately as needed, but in introduced applications this is not needed.

\begin{figure}
	\centering
	\begin{tabular}{cc}
		\includegraphics[width=0.35\columnwidth]{fig2a} &
		\includegraphics[width=0.35\columnwidth]{fig2b} \\ %\hspace{2em} 
		(a) $\mathrm{x}_{i}^k \sim p(\mathrm{x}_i | \mathrm{x}_{i-1}^k)$ & \hspace{2em} 
		(b) $p(\mathrm{z} | \mathrm{x})=\textrm{e}^{Kc_{\mathrm{x}}}$ \\
	\end{tabular}
	\caption{Functions used in the prediction and update steps of the SMC filtering: (a) the prediction importance sampling distribution (for ease of visualization a 2D example is given) and (b) the measurement likelihood function for different values of $K$.}
	\label{fig2}% fig:pred-lhood
\end{figure}

\subsection{Seed Extraction}
\label{subsec:seed-extraction}
To initialize the branch tracing, a set of seed points is extracted (Fig.~\ref{ch4_fig1}B). These seeds are points with very high likelihood of being centered on a branch. In presented method, this likelihood is estimated using a Hessian-based multiscale tubularity filter \cite{frangi1998multiscale}. For each voxel location $\mathrm{p} = [x,y,z]$ this filter yields not only an estimate of the tubularity of the local image structure, but also an estimate of the structure's orientation $\mathrm{v} = [ v_x, v_y, v_z ]$ as derived from the Hessian eigenvector corresponding to the smallest absolute eigenvalue, and an estimate of its spatial scale as derived from the Gaussian $\sigma$ at which the filter yields the highest tubularity value. From the resulting tubularity map, seeds $\mathrm{s}_i = [ \mathrm{p}_i, \mathrm{v}_i, \sigma_i ]$ are selected whose tubularity value is the highest in a cylindrical neighborhood with radius $3\sigma_i$, centered at $\mathrm{p}_i$, and oriented along $\mathrm{v}_i$. A find-maxima function ported from ImageJ is used here. It applies a noise tolerance $\tau$ to prune insignificant local maxima \cite{ferreira2012imagej}.

\subsection{Branch Tracing}
\label{subsec:branch-tracing}
For each seed $\mathrm{s}_i$, this method traces the local image structure in two directions, $+\mathrm{v}_i$ and $-\mathrm{v}_i$, producing a pair of local traces (Fig.~\ref{ch4_fig1}C). A trace is considered to consist of a sequence of hidden states, $\mathrm{x}_{0:L} = (\mathrm{x}_0,\dots,\mathrm{x}_L)$, where $\mathrm{x}_0$ is the initial state extrapolated from the seed $s_i$, and $\mathrm{x}_L$ is the last state of the trace. Similar to the seeds, the states $\mathrm{x}_i = \left[ \mathrm{p}_i, \mathrm{v}_i, \sigma_i \right]$ contain estimates of the position $\mathrm{p}_i = \left[ x_i, y_i, z_i  \right]$, the direction $\mathrm{v}_i = \left[ v_{x_i}, v_{y_i}, v_{z_i} \right]$, and the scale $\sigma_i$ of the underlying neuron branch. The states are estimated sequentially in a probabilistic fashion using Bayes' rule:
\begin{equation}
p(\mathrm{x}_i | \mathrm{z}_{0:i}) \propto  p(\mathrm{z}_i | \mathrm{x}_i) \!\!\int\!\! p(\mathrm{x}_i | \mathrm{x}_{i-1}) p(\mathrm{x}_{i-1} | \mathrm{z}_{0:i-1}) \mathrm{dx}_{i-1}
\label{eq:posterior}
\end{equation}
where $p(\mathrm{x}_i | \mathrm{z}_{0:i})$ is the posterior probability distribution of the state $\mathrm{x}_i$ given measurements $\mathrm{z}_{0:i}$ from the first to the current iteration, $p(\mathrm{x}_i | \mathrm{x}_{i-1})$ is the state transition prior, and $p(\mathrm{z}_i | \mathrm{x}_i)$ is the likelihood of measuring $\mathrm{z}_i$ given state $\mathrm{x}_i$. It is assumed that the state transition is a Markovian process and the measurements are independent. To allow for nonlinearities in the process, the estimation problem (\ref{eq:posterior}) is solved using sequential Monte Carlo (SMC) filtering \cite{doucet2001introduction}, also known as particle filtering \cite{arulampalam2002tutorial}. Here the posterior is approximated using a set of $N$ samples $\mathrm{x}_{i}^k$ with corresponding weights $w_i^k$ as:
\begin{equation}
p(\mathrm{x}_i | \mathrm{z}_{0:i}) \approx \sum_{k=1}^{N} w_i^k \delta(\mathrm{x}_i - \mathrm{x}_i^k)
\label{eq:approx}
\end{equation}
where the weights are normalized so that $\sum_k w_i^k = 1$.

Each iteration in SMC filtering consists of a prediction step and an update step. In the prediction step, given the samples $\mathrm{x}_{i-1}^k$ from the previous iteration, $N$ new samples $\mathrm{x}_i^k$ are drawn using the state transition prior. The importance sampling distribution that is used for this is (Fig.~\ref{fig2}a):
\begin{equation}
p(\mathrm{x}_i  | \mathrm{x}_{i-1}^k) =
\begin{cases}
\displaystyle\frac{\exp\left(\kappa\,\mathrm{v}_i \cdot \mathrm{v}_{i-1}^k -\ \frac{(d_i-d)^2}{2 (d/3)^2} -\ \frac{(\sigma_i-\sigma_{i-1}^k)^2}{2\zeta^2} \right)}{2 \pi I_0(\kappa)\eta} \\[2ex]
\begin{aligned}
& \qquad\text{for $d_i \leq 2d \land \sigma_i \leq 3\zeta$} \\
0 & \qquad\text{otherwise}
\end{aligned}
\end{cases}
\label{eq:pred}
\end{equation}
where $I_0$ denotes the zero-order Bessel function of the first kind, $\kappa$ is the circular variance parameter, $\eta$ is a normalization factor that makes the prediction over all $N$ samples integrate to unity, $d_i= || \mathrm{p}_i - \mathrm{p}_{i-1}^k ||$ is the Euclidean distance between the predicted position and the sample position in the previous iteration, $d$ is the tracing step size, and $\zeta$ the scale variance parameter. Each predicted state is assigned a unit direction $\mathrm{v}_i = (\mathrm{p}_i - \mathrm{p}_{i-1}^k) / || \mathrm{p}_i - \mathrm{p}_{i-1}^k ||$ defined by two consecutive positions. And $\sigma_i-\sigma_{i-1}^k$ represents the difference in scales, which contributes to the importance sampling function by a Gaussian component, giving a higher value to state samples that retain the scale.

In the update step, the newly drawn samples are updated using the following likelihood function (Fig.~\ref{fig2}b):
\begin{equation}
p(\mathrm{z} | \mathrm{x}) = e^{K c_{\mathrm{x}}}
\end{equation}
where $K$ determines the sensitivity to the normalized cross-correlation $c_{\mathrm{x}}\in[-1,1]$, which quantifies the similarity of the underlying image structure for $\mathrm{x}=\left[ \mathrm{p}, \mathrm{v}, \sigma \right]$ to a cylindrical template model with Gaussian profile (Fig.~\ref{fig3}):
\begin{equation}
\label{eq:corr}
c_\mathrm{x} = 
\frac{
	\sum_{k,l,m}
	\left(I(\mathrm{p}')-\bar{I}\,\right) \left(G_{\sigma}-\bar{G}\,\right)
}{
	\!\!\sqrt{
		\sum_{k,l,m}\left(I(\mathrm{p}')-\bar{I}\,\right)^2
		\sum_{k,l,m}\left(G_{\sigma}-\bar{G}\,\right)^2}
}
\end{equation}
\begin{equation}
\label{eq:pp}
\mathrm{p}' = \mathrm{p}'(k,l,m) =  \mathrm{p} + k \mathrm{u} + l \mathrm{w} + m \mathrm{v}
\end{equation}
\begin{equation}
\label{eq:template}
G_{\sigma} = G_{\sigma}(k,l,m)=G_{\sigma}(k,l)=\exp\left(-\big(k^2+l^2\big)/2\sigma^2\right)
\end{equation} 
where $(k,l,m)$ are the template coordinates, which transform to $\mathrm{p}'$ in image coordinates since the template is centered at $\mathrm{p}$ and is oriented in the direction $\mathrm{v}$ and has  scale $\sigma$ of $\mathrm{x}$, and by definition $\mathrm{u} \! \perp \! \mathrm{v}$, $\mathrm{w} \! \perp \! \mathrm{v}$, and $\mathrm{u} \! \perp \! \mathrm{w}$. The summation is limited to $\floor*{-3\sigma} \leq k, l \leq \ceil*{3\sigma}$ and $\floor*{\sigma} \leq m \leq \ceil*{\sigma}$ which corresponds to the spatial extent of the template. $\bar{I}$ and $\bar{G}$ denote the mean of the image intensities and of the template intensities, respectively, within the mentioned limits. The value of $c_\mathrm{x}$ is independent of intensity scalings and offsets and thus provides us with a robust measure of structural resemblance, which may range from $-1$ (inverse correlation), to $0$ (no correlation), to $+1$ (full correlation). The weights of the samples are updated accordingly as:
\begin{equation} 
\label{eq:w-update}
w_i^k \propto w_{i-1}^k
p(\mathrm{x}_{i}^k | \mathrm{x}_{i-1}^k)
\,\textrm{e}^{K c_{\mathrm{x}_i^k}}
\end{equation}
and renormalized so that $\sum_k w_i^k = 1$. To avoid weight deterioration, systematic resampling \cite{kitagawa1996monte} is performed each time the effective sample size $N_{\text{eff}}$ \cite{kong1994sequential} falls below 80\% of $N$. The final state estimate after each iteration $i$, which constitutes a node of the trace, is computed from the weighted samples as the centroid:
\begin{equation} 
\hat{\mathrm{x}}_i = \sum_k w_i^k \mathrm{x}_i^k
\end{equation} 

\begin{figure}
	\centering
	\begin{tabular}{cc}
		\includegraphics[width=0.3\columnwidth]{fig3a} &
		\includegraphics[width=0.3\columnwidth]{fig3b} \\
		(a) 3D  & (b)  2D
	\end{tabular}
	\caption{Cylindrical template intensity model $G_{\sigma}$. The model has a Gaussian profile in coordinates $k$ and $l$ and is constant in coordinate $m$. Both the 3D (a) and the 2D (b) version is shown.}
	\label{fig3}
\end{figure}

Filtering is terminated if the average correlation value $\sum_{k} c_{\mathrm{x}_i^k}/N$ drops below the threshold $c_{\text{min}}$, indicating the end of the underlying neuron branch in the image, or if the iteration limit $L$ is reached. Since the filtering is done for each seed, and in both (opposite) directions, the same neuron branch may be traced many times over, but in a probabilistically independent way, providing accumulating evidence about the presence and location of the branches. However, to avoid excessive over-tracing and to reduce the computation time, the method also monitors the node density $D_n$ per image volume unit $n \times n \times n$ and terminate the tracing if the density in the current position exceeds the limit $\delta_n$.

\subsection{Trace Refinement}
\label{subsec:trace-refinement}
After the tracing step, each neuron branch may have multiple corresponding traces, and each trace node has bidirectional links to neighboring nodes (Figs.~\ref{ch4_fig1}D and \ref{fig4}A) to allow trace traversal in any of the possible directions in the final tree construction step. Denoting the total number of traces by $T$, and the nodes of any given trace $t$ by $n_i^t$, $i=1,\dots,M^t$, it is possible to write the complete set of nodes as:
\begin{equation}
\label{eq:N}
\mathcal{N} = \bigg\{
\Big\{ n_1^1,\dots,n_{M^1}^1\Big\},
\dots,
\Big\{ n_1^T,\dots,n_{M^T}^T\Big\}
\bigg\}
\end{equation}
but in the sequel, the elements of $\mathcal{N}$ are written more generally as $n_k$, $k=1,\dots,M$, where $M=\sum_{t=1}^{T}M^t$. Each node $n_k$ contains an estimate of the center position $\left(x,y,z\right)$ and the cross-sectional radius $\left(r\right)$ of the underlying branch structure, as well as the cross-correlation $\left(c\right)$ with the cylindrical Gaussian template model, and a set $\left( \mathcal{I} \right)$ containing the indices in $\mathcal{N}$ of the neighboring nodes:
\begin{equation}
\label{eq:n_k}
n_k = \lbrace x_k, y_k, z_k, r_k, c_k, \mathcal{I}_k \rbrace
\end{equation}
where $\mathcal{I}_k$ has either two elements (in the case of a body node) or just one (in the case of a terminal node).

The goal of the trace refinement step is to exploit the cumulative evidence provided by the over-tracing in the previous step to improve the individual node estimates. Specifically, each node $n_k$ is updated to:
\begin{equation}
\label{eq:bar_n_k}
\bar{n}_k = \lbrace \bar{x}_k, \bar{y}_k, \bar{z}_k, \bar{r}_k, \bar{c}_k, \bar{\mathcal{I}}_k \rbrace
\end{equation}
by applying mean-shifting \cite{cheng1995mean}, resulting in an updated node set $\bar{\mathcal{N}}$. Mean-shifting iteratively moves each node element to the local mean of the nodes in its vicinity. This reduces the variance of the estimates but preserves the linking of the nodes: $\bar{\mathcal{I}}=\mathcal{I}$. In practice, five iterations are sufficient to reach satisfactory radial trace alignment (Fig.~\ref{fig4}B). The kernel size used in the mean-shifting process is taken to be the initial radius of each node. In the implementation, prior to mean-shifting, all traces are resampled with a step size of one voxel to get a more fine-grained result.
\begin{algorithm}
	\caption{Node grouping.}
	\label{alg:grouping}
	\begin{algorithmic}[1]
		\Require $\bar{\mathcal{N}}$, $r_g$ \Comment{refined node list and grouping radius}
		\State $G = \left[ 0, \dots, 0 \right]$ \Comment{initialize node group mapping list $| G | = | \bar{\mathcal{N}} | = M$}
		\State $\hat{\mathcal{N}} = \lbrace \rbrace $ \Comment{initialize group node set $| \hat{\mathcal{N}} | = 0$}
		\For{$k = \argmax_k \bar{c}_k, \dots, \argmin_k \bar{c}_k $} \Comment{descending correlation}
		\If {$G[k] = 0$} \label{alg:grouping:gFalse}\Comment{initialize new group if yet ungrouped}
		\State $m = | \hat{\mathcal{N}} | + 1$ \Comment{next node group index}
		\State $G[k] = m$ \Comment{fill node group mapping}
		\State $t = 1$ \Comment{index group elements}
		\State $\left(x'_t, y'_t, z'_t, r'_t, c'_t \right) = \left(\bar{x}_k, \bar{y}_k, \bar{z}_k, \bar{r}_k, \bar{c}_k \right) $  \Comment{initialize centroid}
		\State $ \mathcal{I}'_t = \bar{\mathcal{I}}_k $ \Comment{initialize link}
		\For{$l = 1,\dots,k-1, k+1,\dots,M$} \Comment{all other nodes}
		\If {$ (\bar{x}_{l} - \bar{x}_{k})^2 + (\bar{y}_{l} - \bar{y}_{k})^2 +  (\bar{z}_{l} - \bar{z}_{k})^2  \leq r_g^2$} \label{alg:grouping:sphere}
		\State $t = t + 1$	
		\State $x'_t = \frac{t-1}{t} x'_{t-1} + \frac{1}{t} \bar{x}_l$ \Comment{iterative mean}
		\State $y'_t = \frac{t-1}{t} y'_{t-1} + \frac{1}{t} \bar{y}_l$
		\State $z'_t = \frac{t-1}{t} z'_{t-1} + \frac{1}{t} \bar{z}_l$ 
		\State $r'_t = \frac{t-1}{t} r'_{t-1} + \frac{1}{t} \bar{r}_l$
		\State $c'_t = \frac{t-1}{t} c'_{t-1} + \frac{1}{t} \bar{c}_l$
		\State $\mathcal{I}'_t = \mathcal{I}'_{t-1}\cup\bar{\mathcal{I}}_l$	\Comment{accumulate node linkage}			
		\State $G[l] = m$ \Comment{fill node group mapping}
		\EndIf
		\EndFor	
		\State $\hat{n}_m = \left(x'_t,y'_t,z'_t,r'_t,c'_t,\mathcal{I}'_t\right)$ \Comment{assign group values}
		\State $\hat{\mathcal{N}}=\hat{\mathcal{N}}\cup\lbrace\hat{n}_m\rbrace$ \Comment{add node group}
		\EndIf
		\EndFor
		\For{$k = 1, \dots, P $} \Comment{$P = | \hat{\mathcal{N}} |$} 
		\State $ \hat{\mathcal{I}}_k = \text{group}(\hat{\mathcal{I}}_k, G)$ \label{alg:grouping:gMapping} \Comment{turn node to group node indices}
		\State $ \hat{\mathcal{I}}_k = \text{unique}(\hat{\mathcal{I}}_k) $ \Comment{remove repeating indexes}
		\State $ \hat{\mathcal{I}}_k = \hat{\mathcal{I}}_k \setminus \{k\} $ \Comment{remove self-links}
		\EndFor
	\end{algorithmic}
\end{algorithm}

\subsection{Node Grouping}
\label{subsec:node-grouping}
Although the previous step results in refined node estimates, it keeps the total number of nodes and corresponding multiple traces. The next step is to merge overlapping traces and obtain a single trace for each neuron branch. This is accomplished with the node grouping process (Figs.~\ref{ch4_fig1}E and \ref{fig4}C) as detailed in Algorithm~\ref{alg:grouping}. It iteratively takes from the refined set $\bar{\mathcal{N}}$ an as-yet ungrouped node with the highest cross-correlation value, finds all its neighboring nodes within the predefined Euclidean distance $r_g$, and groups them by calculating the mean value of each element while accumulating all node links and mapping their indexes to the group node index list. This results in a new set $\hat{\mathcal{N}} = \lbrace \hat{n}_1,\dots,\hat{n}_P \rbrace$, $P \leq M$, of group nodes:
\begin{equation}
\label{eq:hat_n_k}
\hat{n}_k=\lbrace\hat{x}_k, \hat{y}_k, \hat{z}_k, \hat{r}_k, \hat{c}_k, \hat{\mathcal{I}}_k\rbrace
\end{equation}
and any two $\hat{n}_i$ and $\hat{n}_j$ are connected if there exists a link between any of the refined nodes captured by these two, as revealed by the accumulated index sets $\hat{\mathcal{I}}_i$ and $\hat{\mathcal{I}}_j$. Thus, all existing inter-node connections $\bar{\mathcal{I}}$ are preserved, and are projected into the inter-group connections $\hat{\mathcal{I}}$.
\begin{figure}
	\centering
	\includegraphics[width=0.7\columnwidth]{fig4}
	\caption{Trace merging: (A) accumulated traces, (B) trace refinement, (C) node grouping, (D) tree traversal.}
	\label{fig4}
\end{figure}
\subsection{Tree Construction}
\label{subsec:tree-construction}
The final step of the showcased method is the construction of a graph representing the complete neuronal arbor. This is facilitated by the bidirectional connectivity of the group nodes in $\hat{\mathcal{N}}$. However, similar to a real neuron, the final graph must be a tree, in which the nodes are unidirectionally linked (Figs.~\ref{ch4_fig1}F and \ref{fig4}D), as also required by the SWC file format for storing digital neuron reconstructions \cite{stockley1993system, cannon1998line}. Starting from the soma node, or from the group node with the highest cross-correlation value if no soma was found in the image, the nodes in $\hat{\mathcal{N}}$ are iteratively traversed using a breadth-first search (BFS) algorithm. In this process it is possible to discard any isolated branches and single-node terminal branches (false positives).

\subsection{Implementation Details}
\label{subsec:implementation}
The method showcased in this chapter, named Probabilistic Neuron Reconstructor (PNR)\footnote{The source code of the method is freely available for non-commercial use from \url{https://bitbucket.org/miroslavradojevic/pnr}}, was implemented in C++ as a plugin for the freely available and extendable bioimage visualization and analysis tool Vaa3D \cite{peng2010v3d, peng2014extensible}.\footnote{http://vaa3d.org} As mentioned in the preceding sections, the method has a number of free parameters, which are summarized in Table~\ref{tab:params}, where the default values are also listed.
\begin{table}
	\small\centering
	\begin{tabular}{@{}c@{\hspace{1em}}c@{\hspace{2em}}l@{}}
		\hline
		Parameter & Value & Description \\
		\hline
		$r_s$ & 6 [voxels] & Erosion radius \\
		$\sigma$ & $\{ 2,4,6 \}$ [voxels]  & Scale combinations \\ % \{ \{ 2 \},\{ 2,4 \},\}
		$\tau$ & 10 [8-bit scale] & Local maxima tolerance \\ % $ \{ 8, 10, 12 \} $
		$N$ & 20 & Number of samples \\
		$\kappa$ & 3 [voxels] & Circular variance \\
		$d$ & 3 [voxels] & Tracing step size \\
		$\zeta$ & 1 [voxels] & Scale variance \\
		$K$ & 20 & Likelihood sensitivity \\
		$c_{\text{min}}$ & 0.5 & Correlation threshold \\ % $\lbrace 0.4, 0.5 \rbrace$
		$L$ & 200 & Iteration limit \\
		$n$ & 1 [voxels] & Density volume \\
		$\delta_n$ & 4 [count/voxel] & Node density limit \\
		$r_g$ & 2 [voxels] & Grouping radius \\
		\hline
	\end{tabular}
	\caption{Parameters of the method and default values. The ordering is according to first mention in the main text.}
	\label{tab:params}
\end{table}

\begin{figure}
	\centering
	\begin{tabular}{@{}c@{\hspace{0.5cm}}c@{}}
		\includegraphics[height=0.32\textwidth]{fig5a} &
		\includegraphics[height=0.32\textwidth]{fig5b} \\
		(a) & (b) 
	\end{tabular}
	\caption{Illustration of the synthetic neuron data set used in the presented experiments. (a) Example images of the 10 selected neurons simulated at SNR = 4 and COR = 0.0. (b) Different simulations of the neuron indicated by the red outline in (a) for SNR = 2, 3, 4, 5, and 10 (from left to right) and COR = 0.0, 1.0, and 2.0 (from top to bottom). The marked image in (b) is the same as the marked image in (a). All examples shown here are maximum intensity projections of the 3D synthetic images with inverted intensities for better visualization.}
	\label{fig5}
\end{figure}

\section{Experimental Results}
\label{sec:experimental-results}
The performance of the PNR method was evaluated using both synthetic and real fluorescence microscopy image stacks of single neurons and was compared to several alternative 3D neuron reconstruction methods that yielded favorable performance in the BigNeuron project \cite{peng2015bigneuron}. These included the second all-path pruning method (APP2) \cite{xiao2013app2}, NeuroGPS-Tree (GPS) \cite{quan2016neurogps}, BigNeuron's minimum spanning tree (MST) method, along with the alternative probabilistic method based on probability hypothesis density filtering (PHD) \cite{radojevic2017automated} presented in separate chapter of this thesis.

To quantify performance, evaluation adopted the commonly used measures of distance and overlap of neuron reconstructions with respect to the ground truth (in the case of synthetic images) or the gold-standard reconstructions obtained by manual annotation (in the case of real images). The distance measures were the average minimal reciprocal spatial distance (SD) between nodes in the reconstructions being compared, the substantial spatial distance (SSD) using only the nodes with a spatial distance larger than a threshold S, and the percentage of these substantially distant nodes (\%SSD), all computed after densely resampling each reconstruction to reduce the distance between its adjacent nodes to one voxel (see \cite{peng2010v3d} for details). The overlap measures were precision (P), recall (R), and the F score \cite{powers2011evaluation}, computed from the numbers of true-positive (TP), false-positive (FP) and false-negative (FN) nodes according to the spatial distance threshold S.

All experiments were performed on a MacBook Pro with 2.2 GHz Intel Core i7 processor and 16 GB RAM memory to test the practicality of the methods on a typical computer system. For each method the score was optimized for each performance measure by exploring a grid of possible parameter values around the default ones (see Table~\ref{tab:params} for PNR method and the cited publications for the other methods). To keep the experiments feasible, the maximum allowed processing time per stack and method was set to 2 hours. For the conciseness, only the F scores (higher is better) and SSD scores (lower is better) are shown in the sequel, but the conclusions are based on the complete body of results.

\subsection{Experiments on Synthetic Neuron Images}
\label{subsec:eval-sim}
Prior to evaluating how well introduced method emulates expert manual reconstruction in real neuron images, a controlled experiment was first performed using synthetic neuron images, with known ground-truth reconstructions and predefined levels of signal-to-noise ratio (SNR) and inter-voxel correlation (COR). This allowed us to study the robustness of the method compared to the others as a function of these image quality factors. For this experiment 10 neurons were selected from the BigNeuron training data set \cite{peng2015bigneuron}, representative of the range of morphological complexities in the data set, and for which node radius information (non-default) was available in the corresponding gold-standard reconstructions in SWC format.
\begin{figure}
	\centering
	\begin{subfigure}{0.47\textwidth} 
		\centering\tiny
		\begin{tabular}{c@{\hspace{0.02\textwidth}}c@{}c@{}}
	& \hspace{2.5em}S = 2 & \hspace{2.5em}S = 3 \\[0.5em]
	\rotatebox[origin=c]{90}{COR = 0} &
	\includegraphics[align=c,width=0.48\textwidth]{fig6a} &
	\includegraphics[align=c,width=0.48\textwidth]{fig6b} \\
	\\[0.01\columnwidth]
	\rotatebox[origin=c]{90}{COR = 1} &
	\includegraphics[align=c,width=0.48\textwidth]{fig6c} &
	\includegraphics[align=c,width=0.48\textwidth]{fig6d}
		\end{tabular}
		\caption{Examples are shown for COR = 0 (top) and 1 (bottom) in combination with S = 2 (left) and 3 (right).}
		\label{fig6}
	\end{subfigure}
	\hspace{0.01\textwidth}
	\begin{subfigure}{0.47\textwidth}
		\centering\tiny
		\begin{tabular}{c@{\hspace{0.02\textwidth}}c@{}c@{}}
	& \hspace{2.5em}S = 2 & \hspace{2.5em}S = 3 \\[0.5em]
	\rotatebox[origin=c]{90}{COR = 0} &
	\includegraphics[align=c,width=0.48\textwidth]{fig7a} &
	\includegraphics[align=c,width=0.48\textwidth]{fig7b} \\
	\\[0.01\textwidth]
	\rotatebox[origin=c]{90}{COR = 1} &
	\includegraphics[align=c,width=0.48\textwidth]{fig7c} &
	\includegraphics[align=c,width=0.48\textwidth]{fig7d}
		\end{tabular}
		\caption{Examples are shown for COR = 0 (top) and 1 (bottom) in combination with S = 2 (left) and 3 (right).}
		\label{fig7}
	\end{subfigure}
	\caption{Average score of the methods for the synthetic images as a function of SNR: a) F score and b) SSD score. }
	\label{fig6and7}
\end{figure}
A dedicated plugin for ImageJ \cite{schneider2012nih} called SWC2IMG was developed for this purpose\footnote{https://github.com/imagescience/SWC2IMG}. The plugin takes any SWC file as input and simulates fluorescence microscopy imaging of all neuronal branches in the file at a specified SNR and COR level, producing an image stack whose true digital reconstruction is the very input. It assumes that in practice, because of the relatively large spatial extent of even a single neuron with its complete arbor, the combination of optical magnification factor and digital image matrix size in real neuron images is typically such that the voxel size is larger than the point spread function (PSF), implying that the partial-volume effect of digitization is more prominent than the optical blurring by the microscope. Based on this, the plugin simulates the imaging simply by estimating for each voxel which fraction of its volume is occupied by the neuron. Next, it simulates noise by using the Poisson noise model representative of optical imaging, which defines SNR as the image intensity inside the neuron above the background, divided by the standard deviation of the noise inside \cite{sheppard2006signal}. And finally, to allow for correlated signal and noise, which was found to improve the visual realism of the simulated images, the plugin also offers the possibility to apply Gaussian smoothing at a specified scale, being the COR parameter, while preserving the SNR level. Generally, the lower the SNR and/or the higher the COR level, the more challenging the data and the reconstruction problem.

Using this plugin a synthetic data set was created containing image stacks for a range of SNR and COR values for each neuron (Fig.~\ref{fig5}). Specifically, SNR = 1, 2, 3, 4, 5, 10, 20, and COR = 0, 0.5, 1, 1.5, 2 were considered. Thus, the generated synthetic data set consisted of 10 (neurons) $\times$ 7 (SNR levels) $\times$ 5 (COR levels) $=$ 350 image stacks, attempted to reconstruct optimally using the five considered methods (APP2, GPS, MST, PHD, PNR) and a parameter grid-search approach. However, some of the images were very challenging, especially the ones with many branches and low SNR or high COR values, causing the methods to sometimes require excessive computation times or even to get stuck altogether. Because of the mentioned time constraint, not all methods were able to complete all the reconstructions, and it turned out that only 7 out of the 10 neurons could be reconstructed by all the methods for all SNR and COR values. Therefore the results are presented only for those.

\begin{figure}
	\centering\tiny
	\begin{tabular}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{}}
		& \hspace{2em}SNR = 2 & \hspace{2em}SNR = 4 & \hspace{2em}SNR = 5 & \hspace{2em}SNR = 10 \\[0.5ex]
		\rotatebox[origin=c]{90}{S = 2} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8a} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8b} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8c} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8d} \\
		\\[0.2ex]
		\rotatebox[origin=c]{90}{S = 3} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8e} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8f} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8g} &
		\includegraphics[align=c,width=0.23\textwidth]{fig8h}
	\end{tabular}
	\caption{Average F score of the methods for the synthetic images as a function of COR. Examples are shown for S = 2 (top) and 3 (bottom) in combination with SNR = 2, 4, 5, 10 (left to right).\vspace{\baselineskip}}
	\label{fig8}
\end{figure}
\begin{figure}
	\centering\tiny
	\begin{tabular}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{}}
		& \hspace{2em}SNR = 2 & \hspace{2em}SNR = 4 & \hspace{2em}SNR = 5 & \hspace{2em}SNR = 10 \\[0.5ex]
		\rotatebox[origin=c]{90}{S = 2} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9a_shift} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9b} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9c} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9d} \\
		\\[0.2ex]
		\rotatebox[origin=c]{90}{S = 3} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9e} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9f} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9g} &
		\includegraphics[align=c,width=0.23\textwidth]{fig9h}
	\end{tabular}
	\caption{Average SSD score of the methods for the synthetic images as a function of COR. Examples are shown for S = 2 (top) and 3 (bottom) in combination with SNR = 2, 4, 5, 10 (left to right).}
	\label{fig9}
\end{figure}
\begin{figure}
	\centering\tiny
	\begin{tabular}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{}}
		& \hspace{2em}SNR = 2 & \hspace{2em}SNR = 4 & \hspace{2em}SNR = 5 & \hspace{2em}SNR = 10 \\[0.5ex]
	    \rotatebox[origin=c]{90}{COR = 0}  &
		\includegraphics[align=c,width=0.23\textwidth]{fig10a} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10b} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10c} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10d} \\
		\\[0.2ex]
		\rotatebox[origin=c]{90}{COR = 1}  &
		\includegraphics[align=c,width=0.23\textwidth]{fig10e} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10f} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10g} &
		\includegraphics[align=c,width=0.23\textwidth]{fig10h}
	\end{tabular}
	\caption{Average F score of the methods for the synthetic images as a function of S. Examples are shown for COR = 0 (top) and 1 (bottom) in combination with SNR = 2, 4, 5, 10 (left to right).\vspace{\baselineskip}}
	\label{fig10}
\end{figure}
\begin{figure}
	\centering\tiny
	\begin{tabular}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{}}
		& \hspace{2em}SNR = 2 & \hspace{2em}SNR = 4 & \hspace{2em}SNR = 5 & \hspace{2em}SNR = 10 \\[0.5ex]
		\rotatebox[origin=c]{90}{COR = 0} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11a} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11b} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11c} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11d} \\
		\\[0.2ex]
		\rotatebox[origin=c]{90}{COR = 1} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11e} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11f} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11g} &
		\includegraphics[align=c,width=0.23\textwidth]{fig11h}
	\end{tabular}
	\caption{Average SSD score of the methods for the synthetic images as a function of S. Examples are shown for COR = 0 (top) and 1 (bottom) in combination with SNR = 2, 4, 5, 10 (left to right).}
	\label{fig11}
\end{figure}
\begin{figure}
	\centering % c@{\hspace{0.2em}}
	\begin{tabular}{c@{\hspace{0.5em}}c@{\hspace{0.2em}}c@{\hspace{0.2em}}c@{\hspace{0.2em}}c@{\hspace{0.2em}}c@{\hspace{0.2em}}c@{\hspace{0.2em}}}
		\rotatebox[origin=c]{90}{SNR = 2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a3} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a4} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12a6} 
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12a}}
		\\[-1ex]
		\rotatebox[origin=c]{90}{SNR = 3} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12b1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12b2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12b3} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12b4} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12b5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12b6}
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12b}}
		\\[-1ex]
		\rotatebox[origin=c]{90}{SNR = 4} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12c1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12c2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12c3} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12c4} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12c5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12c6} 
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12c}} 
		\\[-1ex]
		\rotatebox[origin=c]{90}{SNR = 5}  & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12d1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12d2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12d3} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12d4} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12d5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12d6}
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12d}}
		\\[-1ex]
		\rotatebox[origin=c]{90}{SNR = 10} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12e1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12e2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12e3} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12e4} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12e5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12e6} 
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12e}}
		\\[-1ex]
		& 
		\includegraphics[align=c,width=0.15\textwidth]{fig12f1} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12f2} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12f3} & 
		\includegraphics[align=c,width=0.15\textwidth]{fig12f4} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12f5} &
		\includegraphics[align=c,width=0.15\textwidth]{fig12f6}  
		\\ % \multicolumn{6}{c}{\includegraphics[align=c,width=0.9\textwidth]{fig12f}}
		& & APP2 & GPS & MST & PHD & PNR
	\end{tabular}
	\caption{Visual comparison of neuron reconstructions produced by the considered methods from synthetic image stacks of a single neuron at different SNR levels. The image stacks (generated used COR = 0) are shown as inverted maximum intensity projections (left column) and the reconstructions of the different methods (remaining columns) are shown in red as surface renderings.}
	\label{fig12}
\end{figure}

From the average F and SSD scores of the methods as a function of SNR for a few sample values of COR and S (Figs.~\ref{fig6} and \ref{fig7}) it is possible to observe that, as expected, increasing the SNR generally improves the performance of all methods (increasing F and decreasing SSD scores). It is also noteworthy that the two probabilistic methods (PHD and PNR) are more robust against noise (especially according to F) and that the method proposed in this chapter (PNR) is often superior overall. The results also show that, as expected, increasing the value of COR (which yields more difficult images) has a strong negative impact on the performance of all methods (lower F and higher SSD scores for the same SNR). This is confirmed when looking more in-depth at the results as a function of COR (Figs.~\ref{fig8} and \ref{fig9}). Additionally, again as expected in all cases, further observations indicate that increasing the value of S (meaning being more lenient in matching reconstructions to the ground truth) may also strongly affect the scores of all methods (meaning higher F scores, but in this case also higher SSD scores, as the latter includes only node distances larger than S). This is confirmed when looking explicitly at the performance of the methods as a function of S (Figs.~\ref{fig10} and \ref{fig11}). These results reveal that both the absolute and the relative performance of different methods being compared may depend on S. This is an important observation, since in all studies available in the known existing literature, the somewhat arbitrary value of S = 2 is taken for granted in calculating performance and ranking the methods. Presented results (Figs.~\ref{fig10} and \ref{fig11}) show that taking other values of S may yield a different ranking. Notwithstanding this finding, displayed results also show that under most experimental conditions (SNR, COR, S), the proposed method (PNR) yields superior results. While the alternative, probabilistic neuron tracing method (PHD) \cite{radojevic2017automated} is often a strong competitor, the results indicate that the PNR method is more favorable, which is possible to ascribe to its better models for seed point extraction and branch tracing.

Together, the results of the experiments on synthetic neuron images suggest that tracing the image structures repeatedly and in a statistically independently way, indeed yields more evidence about the underlying neuron branches and leads to better reconstructions. This also follows from a visual comparison of the reconstructions (Fig.~\ref{fig12}). Especially at low SNRs, pruning and fast-marching based methods tend to oversegment the images, while the probabilistic methods still perform relatively well regardless. Even at high SNRs, when most of the methods perform comparably, the proposed method follows the branch structures more closely (see zooms in the last row of Fig.~\ref{fig12}).
\subsection{Experiments on Real Neuron Images}
\label{subsec:eval-real}
In addition to synthetic data, three real neuron image data sets were used to evaluate the absolute and relative performance of the presented method. The first two are the olfactory projection fibers (OPF) data set (9 image stacks) and neocortical layer-1 axons (NCL1A) data set (16 image stacks) from the DIADEM challenge \cite{brown2011diadem}, and the third is part of the BigNeuron (BGN) training data set (76 image stacks) \cite{peng2015bigneuron}, all imaged with fluorescence microscopy (confocal or two-photon) and manually annotated as described in detail in the cited works and corresponding resources. Being the smallest of the three, in terms of both neuronal volume and complexity, OPF is probably the most often used data set in the field. NCL1A is often used as it contains neuronal network-like structures and no clear somas. And BGN is the largest, most diverse, and thus most challenging data set for evaluating neuron reconstruction methods. Together, the 100+ image stacks in these data sets have a wide variety of image qualities and volumes (10 MB to 2 GB per stack) and portray a wide range of neuronal shapes and complexities (Fig.~\ref{fig13}), representative of many studies. For some stacks in the BGN data set, the voxel size was unknown, and in these cases the default x:y:z voxel aspect ratio of 1:1:2 was used, reflecting the typically lower resolution in the depth dimension. Also, because of the mentioned processing time constraint, 3 of the 76 image stacks could not be reconstructed by all methods, so the presented results are based on the remaining 73.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{fig13}
	\caption{Illustration of the real neuron image data sets used in the presented experiments. Examples are shown of (A) the OPF data set (4 of 9 stacks), (B) the NCL1A data set (6 of 16 stacks), and (C) the BGN data set (13 of 76 stacks). Each example shows the maximum intensity projection of the image stack (left panel) but with inverted intensities for better visualization, and the corresponding manual reconstruction (right panel) as a surface rendering (in red), both generated using Vaa3D \cite{peng2010v3d}.}
	\label{fig13}
\end{figure}
The results of the experiments on these three real data sets (Figs.~\ref{fig14}-\ref{fig16}) indicate that, as in the experiments on synthetic data, the probabilistic methods PHD and PNR typically show superior performance in terms of both F and SSD score. Of these two methods, the PNR method proposed in this chapter consistently shows the smallest performance spread, indicating it is more robust than the alternative PHD method. For the BGN data set, being the most diverse of the three, the performance spread (including outliers) of all methods is the largest, and the increase in performance as a function of S is the smallest, as expected. Nevertheless, the PNR method consistently shows the best overall performance especially for this data set. In other words, for any given data set similar to those considered in this study, PNR is the favorable method a priori. Obviously this does not necessarily mean that PNR will give the best reconstruction for each and every image stack in the data set, but simply that the chances are higher. This is confirmed when looking at a few example image stacks from the three data sets and the corresponding best reconstructions produced by the different methods by maximizing the F score in the parameter grid search (Figs.~\ref{fig17}-\ref{fig19}). As these examples show, although PNR often outperforms the other methods, in specific cases one of the other methods may give better reconstructions. But altogether the experimentation results suggest the conclusion that the PNR method showcased throughout this chapter is a valuable addition to the neuron reconstruction toolbox.

\begin{figure}
	\centering
	\begin{tabular}{cc}
		\includegraphics[width=0.35\columnwidth]{fig14a} &
		\includegraphics[width=0.35\columnwidth]{fig14b} \\%[0.01\columnwidth]
		\includegraphics[width=0.35\columnwidth]{fig14c} &
		\includegraphics[width=0.35\columnwidth]{fig14d} 
	\end{tabular}
	\caption{Performance comparison for the OPF data set. Results are shown for the F measure (left column) and SSD measure (right column) and in the form of distributions for S = 2 (standard R box plots in top row) and averages as a function of S (bottom row).}
	\label{fig14}
\end{figure}

\begin{figure}
	\centering
	\begin{tabular}{cc}
		\includegraphics[width=0.35\columnwidth]{fig15a} &
		\includegraphics[width=0.35\columnwidth]{fig15b} \\%[0.01\columnwidth]
		\includegraphics[width=0.35\columnwidth]{fig15c} &
		\includegraphics[width=0.35\columnwidth]{fig15d}
	\end{tabular}
	\caption{Performance comparison for the NCL1A data set. Results are shown for the F measure (left column) and SSD measure (right column) and in the form of distributions for S = 2 (standard R box plots in top row) and averages as a function of S (bottom row).}
	\label{fig15}
\end{figure}

\begin{figure}
	\centering
	\begin{tabular}{c@{}c@{}}
		\includegraphics[width=0.35\columnwidth]{fig16a} &
		\includegraphics[width=0.35\columnwidth]{fig16b} \\%[0.01\columnwidth]
		\includegraphics[width=0.35\columnwidth]{fig16c} &
		\includegraphics[width=0.35\columnwidth]{fig16d}
	\end{tabular}
	\caption{Performance comparison for the BGN data set. Results are shown for the F measure (left column) and SSD measure (right column) and in the form of distributions for S = 2 (standard R box plots in top row) and averages as a function of S (bottom row).}
	\label{fig16}
\end{figure}

\begin{figure}
	\centering
	\begin{tabular}{@{}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{}} 
		& APP2 & GPS & MST & PHD & PNR \\[0.5ex]
		\includegraphics[width=0.158\textwidth]{fig17a} &
		\includegraphics[width=0.158\textwidth]{fig17b} &
		\includegraphics[width=0.158\textwidth]{fig17c} &
		\includegraphics[width=0.158\textwidth]{fig17d} &
		\includegraphics[width=0.158\textwidth]{fig17e} &
		\includegraphics[width=0.158\textwidth]{fig17f} \\[0.5ex]
		& F = 0.885  & F = 0.919  & F = 0.934 & F = 0.921 & F = 0.929 \\
	\end{tabular}
	\caption{Example neuron reconstructions of an image stack from the OPF data set. Shown are the original arbor (volume rendering on the left) and the reconstructions (overlaid surface renderings in red) of the different methods (indicated at the top) corresponding to the best F score (given below each reconstruction) for S = 2 with respect to the available manual reconstruction.}
	\label{fig17}
\end{figure}

\begin{figure}
	\centering
	\begin{tabular}{@{}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{}} 
		& APP2 & GPS & MST & PHD & PNR \\[0.5ex]
		\includegraphics[width=0.158\textwidth]{fig18a} &
		\includegraphics[width=0.158\textwidth]{fig18b} &
		\includegraphics[width=0.158\textwidth]{fig18c} &
		\includegraphics[width=0.158\textwidth]{fig18d} &
		\includegraphics[width=0.158\textwidth]{fig18e} &
		\includegraphics[width=0.158\textwidth]{fig18f} \\[0.5ex]
		& F = 0.792 & F = 0.631 & F = 0.790 & F = 0.810 & F = 0.838 \\
	\end{tabular}
	\caption{Example neuron reconstructions of an image stack from the NCL1A data set. Shown are the original arbor (volume rendering on the left) and the reconstructions (overlaid surface renderings in red) of the different methods (indicated at the top) corresponding to the best F score (given below each reconstruction) for S = 2 with respect to the available manual reconstruction.}
	\label{fig18}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{tabular}{@{}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{\hspace{0.01\textwidth}}c@{}} 
		& APP2 & GPS & MST & PHD & PNR \\[0.5ex]
		\includegraphics[width=0.158\textwidth]{fig19a1} &
		\includegraphics[width=0.158\textwidth]{fig19a2} &
		\includegraphics[width=0.158\textwidth]{fig19a3} &
		\includegraphics[width=0.158\textwidth]{fig19a4} &
		\includegraphics[width=0.158\textwidth]{fig19a5} &
		\includegraphics[width=0.158\textwidth]{fig19a6} \\[0.5ex]
		& F = 0.552 & F = 0.513 & F = 0.719 & F = 0.568 & F = 0.599 \\[2ex]
		\includegraphics[width=0.158\textwidth]{fig19b1} &
		\includegraphics[width=0.158\textwidth]{fig19b2} &
		\includegraphics[width=0.158\textwidth]{fig19b3} &
		\includegraphics[width=0.158\textwidth]{fig19b4} &
		\includegraphics[width=0.158\textwidth]{fig19b5} &
		\includegraphics[width=0.158\textwidth]{fig19b6} \\[0.5ex]
		& F = 0.553  & F = 0.602 & F = 0.570 & F = 0.275 & F = 0.661 \\[2ex]
		\includegraphics[width=0.158\textwidth]{fig19c1} &
		\includegraphics[width=0.158\textwidth]{fig19c2} &
		\includegraphics[width=0.158\textwidth]{fig19c3} &
		\includegraphics[width=0.158\textwidth]{fig19c4} &
		\includegraphics[width=0.158\textwidth]{fig19c5} &
		\includegraphics[width=0.158\textwidth]{fig19c6} \\[0.5ex]
		& F = 0.646 & F = 0.656 & F = 0.619 & F = 0.447 & F = 0.724 \\[2ex]
		\includegraphics[width=0.158\textwidth]{fig19d1} &
		\includegraphics[width=0.158\textwidth]{fig19d2} &
		\includegraphics[width=0.158\textwidth]{fig19d3} &
		\includegraphics[width=0.158\textwidth]{fig19d4} &
		\includegraphics[width=0.158\textwidth]{fig19d5} &
		\includegraphics[width=0.158\textwidth]{fig19d6} \\[0.5ex]
		& F = 0.471 & F = 0.451 & F = 0.413 & F = 0.588 & F = 0.592 \\
	\end{tabular}
	\caption{Example neuron reconstructions of four image stacks from the BGN data set. Shown are the original arbors (volume renderings on the left) and the reconstructions (overlaid surface renderings in red) of the different methods (indicated at the top) corresponding to the best F score (given below each reconstruction) for S = 2 with respect to the available manual reconstruction.}
	\label{fig19}
\end{figure}

\section{Conclusions} 
\label{sec:conclusions}
A new fully automated probabilistic neuron reconstruction method (PNR) based on sequential Monte Carlo filtering is presented in this chapter. It traces individual neuron branches from automatically detected seed points repeatedly but statistically independently to acquire more evidence and to be more robust to noise and other artifacts. The traces are subsequently refined, merged, and put into a tree representation for further analysis. The method was evaluated on both synthetic and real neuron images and compared against various other state-of-the-art neuron reconstruction methods (APP2 GPS, MST, PHD) using commonly used quantitative performance measures (earlier presented F and SSD scores). To obtain realistic synthetic data, a novel simulator (SWC2IMG) was developed that can turn any given SWC file into an image stack of specified quality whose ground truth reconstruction is the input. The evaluation on real data used about 100 single-neuron fluorescence microscopy image stacks of widely varying quality and complexity, with corresponding manual reconstructions serving as the gold standard, from three different data sets used in the DIADEM and BigNeuron studies. The results show conclusively that the proposed method is generally favorable and also outperforms the alternative probabilistic neuron reconstruction method based on probability hypothesis density (PHD) filtering, presented in a dedicated chapter of the thesis. Nevertheless, there still remains much room for further improvement, as none of the quantitative scores were near perfect for any of the considered methods even for high SNR levels and very lenient distance thresholds. Possible directions for future work within the presented probabilistic framework would be to explore other state transition and measurement models. Alternatively, since no single method always performs best on all images of a given data set, and the results of different methods are likely complementary, another possible direction could be to combine multiple methods either during tracing or in a post-processing step. The latter approach is already being explored in the BigNeuron project. But regardless of the outcome of this effort it is possible to draw a conclusion that the method proposed throughout this chapter may already prove to be of great use in many cases.